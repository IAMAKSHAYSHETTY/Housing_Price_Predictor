# -*- coding: utf-8 -*-
"""AIAssignment3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wGQ4Az-vfjsn-LbXttWmLUhZKjZLSBur
"""

import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
import scipy as sp
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn import metrics
from sklearn.metrics import r2_score


import warnings
warnings.filterwarnings('ignore')

train = pd.read_csv('train.csv')
test = pd.read_csv('test.csv')

Target = ['SalePrice']

train.dropna(axis=1, inplace = True)
test.dropna(axis=1, inplace = True)

train.head()

test.head()

train['SaleCondition'].unique()

label = LabelEncoder()

#Label Encoding for train


train['MSZoning'] = label.fit_transform(train['MSZoning'])
train['Street'] = label.fit_transform(train['Street'])
train['LotShape'] = label.fit_transform(train['LotShape'])
train['LandContour'] = label.fit_transform(train['LandContour'])
train['Utilities'] = label.fit_transform(train['Utilities'])
train['LotConfig'] = label.fit_transform(train['LotConfig'])
train['LandSlope'] = label.fit_transform(train['LandSlope'])
train['Neighborhood'] = label.fit_transform(train['Neighborhood'])
train['Condition1'] = label.fit_transform(train['Condition1'])
train['Condition2'] = label.fit_transform(train['Condition2'])
train['BldgType'] = label.fit_transform(train['BldgType'])
train['HouseStyle'] = label.fit_transform(train['HouseStyle'])
train['RoofStyle'] = label.fit_transform(train['RoofStyle'])
train['RoofMatl'] = label.fit_transform(train['RoofMatl'])
train['Exterior1st'] = label.fit_transform(train['Exterior1st'])
train['Exterior2nd'] = label.fit_transform(train['Exterior2nd'])
train['ExterQual'] = label.fit_transform(train['ExterQual'])
train['ExterCond'] = label.fit_transform(train['ExterCond'])
train['Foundation'] = label.fit_transform(train['Foundation'])
train['Heating'] = label.fit_transform(train['Heating'])
train['HeatingQC'] = label.fit_transform(train['HeatingQC'])
train['CentralAir'] = label.fit_transform(train['CentralAir'])
train['KitchenQual'] = label.fit_transform(train['KitchenQual'])
train['Functional'] = label.fit_transform(train['Functional'])
train['PavedDrive'] = label.fit_transform(train['PavedDrive'])
train['SaleType'] = label.fit_transform(train['SaleType'])
train['SaleCondition'] = label.fit_transform(train['SaleCondition'])

test['Street'] = label.fit_transform(test['Street'])
test['LotShape'] = label.fit_transform(test['LotShape'])
test['LandContour'] = label.fit_transform(test['LandContour'])
test['LotConfig'] = label.fit_transform(test['LotConfig'])
test['LandSlope'] = label.fit_transform(test['LandSlope'])
test['Neighborhood'] = label.fit_transform(test['Neighborhood'])
test['Condition1'] = label.fit_transform(test['Condition1'])
test['Condition2'] = label.fit_transform(test['Condition2'])
test['BldgType'] = label.fit_transform(test['BldgType'])
test['HouseStyle'] = label.fit_transform(test['HouseStyle'])
test['RoofStyle'] = label.fit_transform(test['RoofStyle'])
test['RoofMatl'] = label.fit_transform(test['RoofMatl'])
test['ExterQual'] = label.fit_transform(test['ExterQual'])
test['ExterCond'] = label.fit_transform(test['ExterCond'])
test['Foundation'] = label.fit_transform(test['Foundation'])
test['Heating'] = label.fit_transform(test['Heating'])
test['HeatingQC'] = label.fit_transform(test['HeatingQC'])
test['CentralAir'] = label.fit_transform(test['CentralAir'])
test['PavedDrive'] = label.fit_transform(test['PavedDrive'])
test['SaleCondition'] = label.fit_transform(test['SaleCondition'])

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()

trainsc = sc.fit_transform(train)
trainsc

train_data = pd.DataFrame(trainsc, columns=train.columns)

train_data.drop(columns=Target, inplace=True)

train_data

x_train, x_test, y_train, y_test = train_test_split(train_data, train[Target], test_size=0.2, random_state=0)

x_train1, x_val, y_train1, y_val = train_test_split(x_train, y_train, test_size=0.25,random_state=0)

from sklearn.linear_model import LinearRegression

#Using Logistic Regression
LinReg = LinearRegression()

LinReg.fit(x_train1, y_train1)

y_pred_linreg = LinReg.predict(x_val)

r2_score(y_pred_linreg, y_val)

np.sort(LinReg.coef_)
coefficients = pd.concat([pd.DataFrame(x_train1.columns),pd.DataFrame(np.transpose(LinReg.coef_))], axis = 1)

coefficients

from xgboost import XGBRegressor, plot_importance

xgb = XGBRegressor()
xgb.fit(x_train1, y_train1)
y_xgb = xgb.predict(x_val)

r2_score(y_xgb, y_val)

from sklearn.ensemble import GradientBoostingRegressor

gb = GradientBoostingRegressor()
gb.fit(x_train1, y_train1)
y_gb = gb.predict(x_val)

r2_score(y_gb, y_val)

# ploting XGBoost default feature importances
fig = plt.figure(figsize = (18, 10))
title = fig.suptitle("Native Feature Importances from XGBoost", fontsize=14)

ax1 = fig.add_subplot(2, 2, 1)
plot_importance(xgb, importance_type='weight', ax=ax1, color='red')
ax1.set_title("Feature Importance with Feature Weight");

ax2 = fig.add_subplot(2, 2, 2)
plot_importance(xgb, importance_type='cover', ax=ax2, color='red')
ax2.set_title("Feature Importance with Sample Coverage");

ax3 = fig.add_subplot(2, 2, 3)
plot_importance(xgb, importance_type='gain', ax=ax3, color='red')
ax3.set_title("Feature Importance with Split Mean Gain");

!pip install eli5

min(y_xgb)

import eli5
from eli5.sklearn import PermutationImportance

eli5.show_weights(xgb.get_booster())

"""For High Price"""

sale = 0
print('Reference:', y_test.iloc[sale])
print('Predicted:', y_xgb[sale])
eli5.show_prediction(xgb.get_booster(), x_test.iloc[sale],
                     feature_names=list(train_data.columns), show_feature_values=True)

"""For Low price"""

sale = 4
print('Reference:', y_test.iloc[sale])
print('Predicted:', y_xgb[sale])
eli5.show_prediction(xgb.get_booster(), x_test.iloc[sale],
                     feature_names=list(train_data.columns), show_feature_values=True)

#Feature Permutation importance
feat_permut = PermutationImportance(xgb, random_state=33).fit(x_train1, y_train1)
eli5.show_weights(feat_permut, feature_names=list(train_data.columns))

!pip install pdpbox

#Univariate ICE plot
from pdpbox import pdp, get_dataset, info_plots
def plot_pdp(model, df, feature, cluster_flag=False, nb_clusters=None, lines_flag=False):

    # Create the data that we will plot
    pdp_goals = pdp.pdp_isolate(model=model, dataset=df, model_features=df.columns.tolist(), feature=feature)

    # plot it
    pdp.pdp_plot(pdp_goals, feature, cluster=cluster_flag, n_cluster_centers=nb_clusters, plot_lines=lines_flag)
    plt.show()

#PD Plot
plot_pdp(xgb, x_train, 'OverallQual')

#ICE Plot
plot_pdp(xgb, x_train, 'OverallQual', cluster_flag=True, nb_clusters=24, lines_flag=True)

#Shapley Values
!pip install shap

import shap
shap.initjs()

explainer = shap.TreeExplainer(xgb)
shap_values = explainer.shap_values(x_test)

X_shap = pd.DataFrame(shap_values)
X_shap.tail()

print('Expected Value: ', explainer.expected_value)

shap.summary_plot(shap_values, x_test, plot_type="bar", color='red')

shap.initjs()
shap.force_plot(explainer.expected_value, shap_values[0,:], x_test.iloc[0,:])

shap.initjs()
shap.force_plot(explainer.expected_value, shap_values[4,:], x_test.iloc[4,:])

shap.initjs()
shap.force_plot(explainer.expected_value, shap_values[:1000,:], x_test.iloc[:1000,:])

shap.summary_plot(shap_values, x_test)

shap.dependence_plot(ind='LotArea', interaction_index='OverallQual',
                     shap_values=shap_values,
                     features=x_test,
                     display_features=x_test)

